# Backend & ETL System â€“ Kasparro Assignment

This repository contains a **production-style Backend & ETL system** built as part of the **Kasparro Backend & ETL Systems assignment**.

The goal of this project was not only to make things work, but to design a system that is **deployable, resilient, maintainable, and easy to reason about**, similar to real-world backend systems.

---

##  Assignment Focus

This assignment emphasizes **production-grade backend engineering**, including:

- Data ingestion pipelines (ETL)
- Backend APIs
- Dockerization and reproducibility
- Recovery and startup resilience
- Clean, scalable architecture
- Cloud deployment readiness

ğŸ”— **Assignment Document**  
https://drive.google.com/file/d/1KYZ9XLV6ByF7fBcCgHfHmhUsG7yW1all/view

---

## Tech Stack

- **Backend Framework**: FastAPI (Python)
- **Database**: PostgreSQL 14
- **ETL**: Python-based ingestion and transformation
- **Containerization**: Docker & Docker Compose
- **Cloud**: AWS EC2 (Ubuntu)

---

##  System Architecture

## ğŸ§  System Architecture

- **AWS EC2 (Ubuntu)**
  - **FastAPI Backend (Docker)**
    - API layer (health & data endpoints)
    - Startup logic with recovery handling
    - ETL-related initialization
  - **PostgreSQL Database (Docker)**
    - Normalized asset data storage
  - **Docker Compose**
    - Service orchestration
    - Health checks
    - Environment-based configuration




### Key Architectural Decisions
- Backend and database run as **separate containers**
- Containers communicate using Dockerâ€™s internal network
- Database readiness is handled explicitly using **health checks**
- API startup is designed to be **resilient**, not fragile

---

# ğŸ“ Project Folder Structure

This document describes the folder structure of the project and the purpose of each directory.  
The structure is designed to keep concerns separated and support long-term maintainability.

---

## ğŸ—‚ï¸ Directory Layout


kasparro-backend-avinash-kumar/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py
â”‚       â””â”€â”€ FastAPI application entry point and API routes
â”‚
â”œâ”€â”€ core/
â”‚   â””â”€â”€ Shared utilities, configuration helpers, and core logic
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Local data files used for ingestion, testing, or reference
â”‚
â”œâ”€â”€ db/
â”‚   â””â”€â”€ Database connection logic, helpers, and database-related utilities
â”‚
â”œâ”€â”€ ingestion/
â”‚   â””â”€â”€ ETL pipelines and data ingestion workflows
â”‚
â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ Data models and schemas for validation and serialization
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ Unit and integration tests
â”‚
â”œâ”€â”€ .pytest_cache/
â”‚   â””â”€â”€ Pytest cache (auto-generated)
â”‚
â”œâ”€â”€ .env
â”‚   â””â”€â”€ Environment variables for local and containerized execution
â”‚
â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ Docker image definition for the FastAPI service
â”‚
â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ Service orchestration, health checks, and environment configuration
â”‚
â”œâ”€â”€ Makefile
â”‚   â””â”€â”€ Helper commands for development and testing
â”‚
â”œâ”€â”€ pytest.ini
â”‚   â””â”€â”€ Pytest configuration
â”‚
â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Python dependencies
â”‚
â””â”€â”€ README.md
    â””â”€â”€ Project documentation and deployment details



This structure makes it easy to:
- Extend ETL logic
- Add new API endpoints
- Test components independently
- Maintain the system long-term

---

## ğŸŒ External Data Sources (APIs)

The assignment specifies two cryptocurrency APIs:

### API 1: CoinPaprika
- Authenticated API
- Requires an API key
- Intended to test secure credential handling

### API 2: CoinGecko
- Free, open API
- No API key required

### API Usage Note
The system is **architected to support both authenticated and unauthenticated APIs** using environment variables.

- CoinGecko was used as an open data source during development.
- CoinPaprika integration is structured to accept an API key securely via environment variables but was not activated due to the absence of provided credentials.

No API keys are hardcoded.

---

Live Deployment (AWS EC2)

The backend system is deployed on AWS EC2 and is publicly accessible.
Health Check Endpoint:   http://13.51.56.51:8000/health

Sample response:
{
  "status": "ok",
  "database": "connected"
}

This endpoint confirms:
The API service is running
The PostgreSQL database is reachable
The system has started successfully in a cloud environment

## âš™ï¸ Environment Configuration

All configuration is handled through environment variables to ensure security and portability:

```env
DB_HOST=db
DB_PORT=5432
DB_NAME=kasparro
DB_USER=postgres
DB_PASSWORD=avinash79




